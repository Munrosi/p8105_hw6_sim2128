---
title: "HW 6"
author: "Sarah Munro"
date: "11/24/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(mgcv)
library(modelr)
library(purrr)

set.seed(1)
```

# Problem 1

_Load and tidy the dataset_
```{r}
btw = read_csv("./Data/birthweight.csv") %>%
  janitor::clean_names() %>%
  drop_na() %>%
mutate(
  babysex = as.factor(babysex),
  frace = as.factor(frace),
  mrace = as.factor(mrace),
  malform = as.factor(malform)
)
```

_Determine the best model_
```{r}
library(MASS)
full.model = lm(bwt ~., data = btw)
step.model = stepAIC(full.model, direction = "both", 
                      trace = FALSE)
summary(step.model)
```

_I used a stepwise regression to determine the best model by AIC, the resulting model is specified below_
```{r}
model_best = lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = btw)


model_best %>%  
broom::tidy() 
```

_Plot a model of residuals against fitted values_
```{r}
modelr::add_residuals(btw, model_best) %>%
modelr::add_predictions(model_best) %>%
ggplot(aes(x = pred, y = resid)) + geom_violin()
```

```{r}
cv_df = 
  crossv_mc(btw, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df = 
  cv_df %>% 
  mutate(
        model_best  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
         model_a  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_b  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))) %>%  
  mutate(rmse_best = map2_dbl(model_best, test, ~rmse(model = .x, data = .y)),
         rmse_a = map2_dbl(model_a, test, ~rmse(model = .x, data = .y)),
         rmse_b = map2_dbl(model_b, test, ~rmse(model = .x, data = .y)))
``` 
_Compare the cross validated prediction errors of the three models_
```{r}
  cv_df %>% 
  dplyr::select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Model a has the highest rmse, and model best (the model I created) shows the lowest rmse. From this visual comparison I would conclude that my model does the best at predicting baby birthweight. 


# Problem 2

_Load the dataset_
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  dplyr::select(name, id, everything())
```

_Take 5000 bootstrap samples_
```{r}
boot_straps = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    gresults = map(models, broom::glance), 
    tresults = map(models, broom::tidy)) %>%
  dplyr::select(-strap, -models) %>% 
  unnest() %>%
dplyr::select(.id, r.squared, term, estimate)  %>%
pivot_wider(names_from = "term",
            values_from = "estimate") %>%
  janitor::clean_names() %>%
 mutate(
   logbetas = log(intercept*tmin)
 ) 
```

_Plot the distribution of the two estimates_
```{r}
boot_straps %>%
ggplot(aes(x = r_squared)) + geom_histogram() 

boot_straps %>%
ggplot(aes(x = logbetas)) + geom_histogram()
```

The distributo of r_sqaured is relatively normal but slightly left skewed. The distribution of logbetas is normal for the most part. 

_Identify the quantiles to provide a CI_
```{r}
  quantile(pull(boot_straps, r_squared), probs = c(.025, .975)) %>%
  knitr::kable(digits = 3)

  quantile(pull(boot_straps, logbetas), probs = c(.025, .975)) %>%
  knitr::kable(digits = 3)
```
The 95% confidence interval for r_sqaured is (0.894, 0.927) and the confidence interval for log(beta0 * beta1) is (1.956, 2.059)
  
  